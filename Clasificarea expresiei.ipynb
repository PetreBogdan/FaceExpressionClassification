{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d9982bed-bbae-43a5-8e8b-7fdf5b628512",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Importarea modulelor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4290014b-4d64-4c92-9016-92520924b189",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from skimage.io import imshow, imread\n",
    "\n",
    "from sklearn import datasets, ensemble\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn import svm, metrics, datasets\n",
    "\n",
    "from numpy import pi\n",
    "\n",
    "from skimage.feature import hog\n",
    "from skimage import data, exposure\n",
    "from skimage.color import rgb2gray\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f49b5311-6ab2-4abc-a582-4c829e3fc627",
   "metadata": {},
   "source": [
    "## Partea de parsare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "58220b55-f21c-4d94-bbb8-a754ae6b32a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_list = os.listdir('Cohn Kanade_annotations')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed135281-ddfe-4cdb-9934-eb76ecefcdce",
   "metadata": {},
   "source": [
    "## Datele initiale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aea33520-a2a8-44ef-80b4-b2c4f8ee22b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "negative = ['F', 'G', 'A', 'D']\n",
    "positive = ['H', 'S']\n",
    "etichete= []\n",
    "date = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c590080-1841-489e-9813-58b59e54c9c8",
   "metadata": {},
   "source": [
    "### Parsarea etichetelor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3c4e9224-d13b-49af-95d5-d152ebd2bd5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "emotii = []\n",
    "for pers in dir_list:\n",
    "    dir_list_pers = os.listdir('Cohn Kanade_annotations'+ '/' +pers)\n",
    "    # print('Person {}: {}'.format(pers, dir_list_pers))\n",
    "    emotii_pers = []\n",
    "    for emotion in dir_list_pers:\n",
    "        \n",
    "        if emotion[-1] in negative:\n",
    "            emotii_pers.append('N')\n",
    "        else: \n",
    "            emotii_pers.append('P')\n",
    "    emotii.append(emotii_pers)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "948eb24d-2ff3-49c7-850d-33a6190b4fc4",
   "metadata": {},
   "source": [
    "### Parsarea imaginilor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "19cab6ee-9c6f-4c58-b73b-3aa8ad5b2cd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "lista_imagini = []\n",
    "for index1, pers in enumerate(dir_list):\n",
    "    dir_list_pers = os.listdir('Cohn_Kanade_images'+ '/' +pers)\n",
    "    for index2, emotion in enumerate(dir_list_pers):\n",
    "        dir_list_images = os.listdir('Cohn_Kanade_images'+ '/' +pers + '/' +emotion)\n",
    "        for image in dir_list_images[5:]:\n",
    "            if image == 'Thumbs.db':\n",
    "                continue\n",
    "            curr_image = imread('Cohn_Kanade_images'+ '/' +pers + '/' +emotion + '/' + image)\n",
    "            lista_imagini.append(curr_image)\n",
    "            etichete.append(emotii[index1][index2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "448f4296-49a9-4e6c-8f13-c86ba7e26cb6",
   "metadata": {},
   "source": [
    "## Conversia imaginilor in grayscale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bf050b06-a016-4d5a-a8dc-dab609ec3263",
   "metadata": {},
   "outputs": [],
   "source": [
    "lista_imagini_grayscale = []\n",
    "for imagine in lista_imagini:\n",
    "    if len(imagine.shape) == 2:\n",
    "        lista_imagini_grayscale.append(imagine)\n",
    "    else:\n",
    "        gray = rgb2gray(imagine)\n",
    "        lista_imagini_grayscale.append(gray)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75ffef94-8f2b-47d3-b683-c239f71663ac",
   "metadata": {},
   "source": [
    "## Taierea imaginilor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7e99138-4b1f-453e-865e-ec236f7f8bcc",
   "metadata": {},
   "source": [
    "#### OpenCV automat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3f58c73b-50f0-4fae-b616-4d999e56ba03",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "cropped_list = []\n",
    "index = 0\n",
    "for imagine in lista_imagini_grayscale:\n",
    "    \n",
    "    image = np.array(imagine, dtype='uint8')\n",
    "\n",
    "    # Load the cascade\n",
    "    face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_alt2.xml')\n",
    "\n",
    "    # Detect faces\n",
    "    faces = face_cascade.detectMultiScale(image, 1.1, 4)\n",
    "\n",
    "    # we assume an error of 0.03% that  the detected facec is not a real face\n",
    "    if len(faces) != 1:\n",
    "        etichete.pop(index)\n",
    "        continue\n",
    "    index += 1\n",
    "    # Draw rectangle around the faces and crop the faces\n",
    "    for (x, y, w, h) in faces:\n",
    "        cv2.rectangle(image, (x, y), (x+w, y+h), (0, 0, 255), 2)\n",
    "        faces = image[y:y + h, x:x + w]\n",
    "        resized = cv2.resize(faces, dsize=(350, 350), interpolation=cv2.INTER_CUBIC)\n",
    "        cropped_list.append(resized)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b62a1ba-c227-46a5-89af-8ddcb0eddb29",
   "metadata": {},
   "source": [
    "## Aplicarea HOG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "18ba19e0-f790-42fe-8065-852dca4f9979",
   "metadata": {},
   "outputs": [],
   "source": [
    "imagini_hog = []\n",
    "for imagine in cropped_list:\n",
    "    fd, hog_image = hog(imagine, orientations=9, pixels_per_cell=(10, 10),\n",
    "                    cells_per_block=(1, 1), visualize=True)\n",
    "    date.append(fd)\n",
    "    imagini_hog.append(hog_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcaa7580-8b82-4353-b40f-2e9cab02f753",
   "metadata": {},
   "source": [
    "## Impartirea datelor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1f07b538-1cf6-4d67-96f7-b56d079d4a8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4316 1850\n",
      "4316 1850\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split dataset into training set and test set 70-30\n",
    "date_train, date_test, etichete_train, etichete_test = train_test_split(date, etichete, test_size=0.3, random_state=109)\n",
    "print(len(date_train), len(date_test))\n",
    "print(len(etichete_train), len(etichete_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de1b564b-0a61-4a65-908d-e8be82d5ebf2",
   "metadata": {},
   "source": [
    "## Antrenarea si testarea algoritmului"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8ba9537a-cc5d-4051-ba79-f1fc7d16d2ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acuratete test =  0.9794594594594594\n"
     ]
    }
   ],
   "source": [
    "clf = svm.SVC(kernel='linear',C=0.1, gamma=10)\n",
    "clf.fit(date_train,etichete_train)\n",
    "predictii=clf.predict(date_test)\n",
    "\n",
    "acuratete = metrics.accuracy_score(y_true = etichete_test, y_pred = predictii)\n",
    "print('Acuratete test = ',acuratete)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}